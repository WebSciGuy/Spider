![](http://i.imgur.com/wYi2CkD.png)


This fork of the spider project logs linked networks and outputs a CSV file which can then be imported into a graphing package of your choice.

Enter start URL and project name in projectData.py, then run main.py. After completion, run fileFormats.py to create the CSV files.



# Original readme:


# Overview

This is an open source, multi-threaded website crawler written in Python. There is still a lot of work to do, so feel free to help out with development.

***

Note: This is part of an open source search engine. The purpose of this tool is to gather links **only**. The analytics, data harvesting, and search algorithms are being created as separate programs. 

### Links

- [Support thenewboston](https://www.patreon.com/thenewboston)
- [thenewboston.com](https://thenewboston.com/)
- [Facebook](https://www.facebook.com/TheNewBoston-464114846956315/)
- [Twitter](https://twitter.com/bucky_roberts)
- [Google+](https://plus.google.com/+BuckyRoberts)
- [reddit](https://www.reddit.com/r/thenewboston/)
